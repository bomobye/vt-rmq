{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abeefe33-8cd4-42c7-8aa6-bd789d08e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "import html\n",
    "import tiktoken\n",
    "import time\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "from ftfy import fix_text\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "class PhishingEmailPreprocessor:\n",
    "    \"\"\"\n",
    "    Veri ön işleme için yazılan sınıf.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path:str, train_frac:float, validation_frac:float):\n",
    "\n",
    "        self.df = None\n",
    "        self.train_df = None\n",
    "        self.validation_df = None\n",
    "        self.test_df = None\n",
    "\n",
    "        self.train_frac = train_frac\n",
    "        self.validation_frac = validation_frac\n",
    "\n",
    "        self.csv_path = csv_path\n",
    "\n",
    "        self.tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "        self.pad_token_id = 50256\n",
    "        self.max_len = 1024        \n",
    "\n",
    "        self.load_and_prepare(self.csv_path)   \n",
    "\n",
    "    def strip_html(self,text: str) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"    \n",
    "        text = html.unescape(text)\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        return soup.get_text(separator=\" \")\n",
    "\n",
    "    def normalize_whitespace(self,text: str) -> str:\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"        \n",
    "        text = re.sub(r\"\\s+\", \" \", text) \n",
    "        return text.strip()\n",
    "\n",
    "    def fix_unicode(self,text: str) -> str:\n",
    "        if not isinstance(text, str): \n",
    "            return \"\"\n",
    "        return fix_text(text)\n",
    "\n",
    "    def create_balanced_dataset(self):\n",
    "        \n",
    "        num_spam = self.df[self.df[\"Email Type\"] == 1].shape[0]\n",
    "        \n",
    "        ham_subset = self.df[self.df[\"Email Type\"] == 0].sample(num_spam, random_state=123)\n",
    "        \n",
    "        self.df = pd.concat([ham_subset, self.df[self.df[\"Email Type\"] == 1]]) \n",
    "\n",
    "    def load_and_prepare(self,csv_path: str):\n",
    "        self.df = pd.read_csv(csv_path, sep=\",\", header=0, quotechar='\"')\n",
    "\n",
    "        self.df = self.df.dropna(subset=[\"Email Text\", \"Email Type\"])\n",
    "        self.df = self.df[self.df[\"Email Text\"].astype(str).str.strip() != \"\"]\n",
    "\n",
    "        self.df[\"Email Text\"] = self.df[\"Email Text\"].apply(self.fix_unicode)\n",
    "        self.df[\"Email Text\"] = self.df[\"Email Text\"].apply(self.strip_html)\n",
    "        self.df[\"Email Text\"] = self.df[\"Email Text\"].apply(self.normalize_whitespace)\n",
    "\n",
    "        self.df = self.df[self.df[\"Email Text\"].str.len() > 0]\n",
    "\n",
    "        self.df = self.df.drop_duplicates(subset=[\"Email Text\"]).copy()\n",
    "\n",
    "        self.df[\"Email Type\"] = self.df[\"Email Type\"].map({\"Safe Email\": 0, \"Phishing Email\": 1})\n",
    "        self.df = self.df.dropna(subset=[\"Email Type\"])\n",
    "        self.df[\"Email Type\"] = self.df[\"Email Type\"].astype(int)\n",
    "        self.create_balanced_dataset()\n",
    "        self.random_split()\n",
    "        self.train_df[\"Token\"] = self.train_df[\"Email Text\"].apply(self.tokenize)\n",
    "        self.validation_df[\"Token\"] = self.validation_df[\"Email Text\"].apply(self.tokenize)\n",
    "        self.test_df[\"Token\"] = self.test_df[\"Email Text\"].apply(self.tokenize)\n",
    "\n",
    "    def random_split(self):\n",
    "        self.df = self.df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "        train_end = int(len(self.df) * self.train_frac)\n",
    "        validation_end = train_end + int(len(self.df) * self.validation_frac)\n",
    "\n",
    "        self.train_df = self.df[:train_end]\n",
    "        self.validation_df = self.df[train_end:validation_end]\n",
    "        self.test_df = self.df[validation_end:]\n",
    "\n",
    "    def tokenize(self,text):\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        return tokens        \n",
    "    \n",
    "    def get_dfs(self) -> pd.DataFrame:\n",
    "        self.train_df = self.train_df.drop(columns=[\"Unnamed: 0\"])\n",
    "        self.validation_df = self.validation_df.drop(columns=[\"Unnamed: 0\"])\n",
    "        self.test_df = self.test_df.drop(columns=[\"Unnamed: 0\"])\n",
    "        return self.train_df, self.validation_df, self.test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f9c8c8-d1f9-468b-bf0d-28c73a02ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = PhishingEmailPreprocessor(\"C:\\\\Users\\\\user\\\\Desktop\\\\Phishing_Email.csv\\\\Phishing_Email.csv\",0.7,0.2)\n",
    "train_df, validation_df, test_df = preprocessor.get_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef54851c-f1fd-4893-a393-25931b94d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\"\"\"\n",
    "Dataframeden DataLoadera dönüşüm için aşağıdaki 2 sınıf kullanılmıştır.\n",
    "\"\"\"\n",
    "\n",
    "class EmailDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.df.loc[idx, \"Token\"]\n",
    "        label = int(self.df.loc[idx, \"Email Type\"])\n",
    "        return tokens, label\n",
    "\n",
    "\n",
    "class EmailDataLoader:\n",
    "    def __init__(self, train_df, val_df, test_df, batch_size=8, num_workers=0, seed=123):\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.train_dataset = EmailDataset(train_df)\n",
    "        self.val_dataset   = EmailDataset(val_df)\n",
    "        self.test_dataset  = EmailDataset(test_df)\n",
    "        \n",
    "    #Bir batchdeki maksimum token uzunluğunu bulup batch padding yapmak için yazılmıştır.\n",
    "    def make_collate_fn(self, pad_id=preprocessor.pad_token_id, max_len=None):\n",
    "        def collate(batch):\n",
    "            xs, ys = zip(*batch)\n",
    "    \n",
    "            xs_list = [x.tolist() if isinstance(x, torch.Tensor) else x for x in xs]\n",
    "    \n",
    "            if max_len is not None:\n",
    "                xs_list = [x[:max_len] for x in xs_list]\n",
    " \n",
    "            maxlen = max(len(x) for x in xs_list)\n",
    "    \n",
    "            X = [x + [pad_id] * (maxlen - len(x)) for x in xs_list]\n",
    "            Y = list(ys)\n",
    "    \n",
    "            X = torch.tensor(X, dtype=torch.long)\n",
    "            Y = torch.tensor(Y, dtype=torch.long)\n",
    "            return X, Y\n",
    "        return collate\n",
    "\n",
    "    def get_loaders(self):\n",
    "        collate = self.make_collate_fn(pad_id=preprocessor.pad_token_id, max_len=preprocessor.max_len)\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=True,\n",
    "            collate_fn=collate,\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            dataset=self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=False,\n",
    "            collate_fn=collate,\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            dataset=self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            drop_last=False,\n",
    "            collate_fn=collate,\n",
    "        )\n",
    "\n",
    "        return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4e4a60c-c0f0-45b9-9345-957d14651d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = EmailDataLoader(train_df, validation_df, test_df, batch_size=16)\n",
    "train_loader, val_loader, test_loader = data_module.get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22823730-d41a-40f9-8781-1bc8c7b04220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Sınıfı.\n",
    "    \"\"\"    \n",
    "    \n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads #\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) \n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "\n",
    "\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2807907d-51de-4a96-8efd-84af42c7ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Aktivasyon fonksiyonu için yazılmış sınıf.\n",
    "    \"\"\"    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x) \n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut \n",
    "\n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Kullanılacak modelimiz.\n",
    "    \"\"\"          \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53bf9214-719e-44d8-855b-6fbd4185dd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Modeli huggingface'den indirip config bilgisi ile yükledim.\n",
    "file_name = \"D:\\\\llm\\\\model\\\\gpt2-small-124M.pth\"\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 1024, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": True       # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed32247a-0c98-4b0c-94cc-72c98df04992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eğitime başlamadan önce tüm ağırlıkları dondurdum.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e98b83d-a9b4-4430-bce6-bfac7b111ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "#Modelin son kısmını 2 çıkışlı network ile değiştirdim.\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=GPT_CONFIG_124M[\"emb_dim\"], out_features=num_classes)\n",
    "model.out_head = model.out_head.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd444457-ba1f-45d3-9ae9-cb41293fc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Son transformer block ve finalLayerNorm kısmını eğitim amaçlı açtım.\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44a0d71-9619-4a40-91e0-5d5039e77b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = 50256\n",
    "\n",
    "#Modelde attentionda PAD mask olmadığı için en son valid token almak için yazıldı.\n",
    "def last_valid_logits(xb, model, device, pad_id=PAD_ID):\n",
    "    xb = xb.to(device)\n",
    "    last_idx = (xb != pad_id).sum(dim=1) - 1\n",
    "    logits_all = model(xb)  # [B, T, C]\n",
    "    return logits_all[torch.arange(xb.size(0), device=device), last_idx, :]  # [B, C]\n",
    "\n",
    "#cross_entropy loss kullandım.\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = last_valid_logits(input_batch, model, device, PAD_ID)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        \n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = last_valid_logits(input_batch, model, device, PAD_ID)\n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a811fa6a-5f8c-463f-b058-7535608f5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math, torch\n",
    "\n",
    "#Eğitim için early stopping ile kullanacağımız fonksiyon\n",
    "def train_classifier_simplev2(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter,\n",
    "    early_stopping=True, patience=3, min_delta=1e-3,\n",
    "    restore_best_weights=True, checkpoint_path=None\n",
    "):\n",
    "    # Takip listeleri\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Early stopping durum değişkenleri\n",
    "    best_val_loss = math.inf\n",
    "    best_state_dict = None\n",
    "    epochs_no_improve = 0\n",
    "    best_epoch = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() \n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "\n",
    "            if global_step % eval_freq == 0 and global_step > 0:\n",
    "\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter=eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "\n",
    "        epoch_train_loss, epoch_val_loss = evaluate_model(\n",
    "            model, train_loader, val_loader, device, eval_iter=None  # tamamını tara\n",
    "        )\n",
    "\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy   = calc_accuracy_loader(val_loader,   model, device, num_batches=eval_iter)\n",
    "        print(f\"[Epoch {epoch+1}] mean Train loss {epoch_train_loss:.3f}, mean Val loss {epoch_val_loss:.3f}\")\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "        # ---- EARLY STOPPING KONTROLÜ ----\n",
    "        if early_stopping:\n",
    "            improved = (best_val_loss - epoch_val_loss) > min_delta\n",
    "            if improved:\n",
    "                best_val_loss = epoch_val_loss\n",
    "                best_epoch = epoch + 1\n",
    "                epochs_no_improve = 0\n",
    "                if restore_best_weights:\n",
    "                    best_state_dict = copy.deepcopy(model.state_dict())\n",
    "                if checkpoint_path:  # opsiyonel diske kaydet\n",
    "                    torch.save(model.state_dict(), checkpoint_path)\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "                if epochs_no_improve >= patience:\n",
    "                    print(f\"Early stopping: {patience} epoch boyunca anlamlı iyileşme yok. \"\n",
    "                          f\"En iyi Val loss {best_val_loss:.4f} (epoch {best_epoch}).\")\n",
    "                    if restore_best_weights and best_state_dict is not None:\n",
    "                        model.load_state_dict(best_state_dict)\n",
    "                        print(\"Best weights geri yüklendi.\")\n",
    "                    break\n",
    "        # ---- /EARLY STOPPING ----\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde10bd6-e6d8-4615-a3b8-a7a31ee9b38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000200): Train loss 1.225, Val loss 1.574\n",
      "Ep 1 (Step 000400): Train loss 0.461, Val loss 0.828\n",
      "[Epoch 1] mean Train loss 0.716, mean Val loss 0.719\n",
      "Training accuracy: 64.06% | Validation accuracy: 71.88%\n",
      "Ep 2 (Step 000600): Train loss 0.747, Val loss 0.692\n",
      "Ep 2 (Step 000800): Train loss 0.634, Val loss 0.596\n",
      "Ep 2 (Step 001000): Train loss 0.530, Val loss 0.522\n",
      "[Epoch 2] mean Train loss 0.404, mean Val loss 0.416\n",
      "Training accuracy: 84.38% | Validation accuracy: 78.12%\n",
      "Ep 3 (Step 001200): Train loss 0.449, Val loss 0.456\n",
      "Ep 3 (Step 001400): Train loss 0.234, Val loss 0.402\n",
      "Ep 3 (Step 001600): Train loss 0.162, Val loss 0.367\n",
      "[Epoch 3] mean Train loss 0.231, mean Val loss 0.251\n",
      "Training accuracy: 93.75% | Validation accuracy: 79.69%\n",
      "Ep 4 (Step 001800): Train loss 0.224, Val loss 0.348\n",
      "Ep 4 (Step 002000): Train loss 0.119, Val loss 0.341\n",
      "Ep 4 (Step 002200): Train loss 0.173, Val loss 0.337\n",
      "[Epoch 4] mean Train loss 0.164, mean Val loss 0.189\n",
      "Training accuracy: 92.19% | Validation accuracy: 85.94%\n",
      "Ep 5 (Step 002400): Train loss 0.129, Val loss 0.330\n",
      "Ep 5 (Step 002600): Train loss 0.115, Val loss 0.334\n",
      "Ep 5 (Step 002800): Train loss 0.126, Val loss 0.320\n",
      "[Epoch 5] mean Train loss 0.129, mean Val loss 0.156\n",
      "Training accuracy: 96.88% | Validation accuracy: 85.94%\n",
      "Ep 6 (Step 003000): Train loss 0.073, Val loss 0.313\n",
      "Ep 6 (Step 003200): Train loss 0.145, Val loss 0.319\n",
      "Ep 6 (Step 003400): Train loss 0.085, Val loss 0.315\n",
      "[Epoch 6] mean Train loss 0.112, mean Val loss 0.141\n",
      "Training accuracy: 93.75% | Validation accuracy: 87.50%\n",
      "Ep 7 (Step 003600): Train loss 0.132, Val loss 0.306\n",
      "Ep 7 (Step 003800): Train loss 0.120, Val loss 0.306\n",
      "[Epoch 7] mean Train loss 0.100, mean Val loss 0.132\n",
      "Training accuracy: 95.31% | Validation accuracy: 85.94%\n",
      "Ep 8 (Step 004000): Train loss 0.035, Val loss 0.288\n",
      "Ep 8 (Step 004200): Train loss 0.032, Val loss 0.269\n",
      "Ep 8 (Step 004400): Train loss 0.039, Val loss 0.271\n",
      "[Epoch 8] mean Train loss 0.097, mean Val loss 0.132\n",
      "Training accuracy: 96.88% | Validation accuracy: 87.50%\n",
      "Ep 9 (Step 004600): Train loss 0.078, Val loss 0.261\n",
      "Ep 9 (Step 004800): Train loss 0.101, Val loss 0.246\n",
      "Ep 9 (Step 005000): Train loss 0.050, Val loss 0.238\n",
      "[Epoch 9] mean Train loss 0.075, mean Val loss 0.107\n",
      "Training accuracy: 98.44% | Validation accuracy: 87.50%\n",
      "Ep 10 (Step 005200): Train loss 0.027, Val loss 0.233\n",
      "Ep 10 (Step 005400): Train loss 0.028, Val loss 0.221\n",
      "Ep 10 (Step 005600): Train loss 0.043, Val loss 0.214\n",
      "[Epoch 10] mean Train loss 0.066, mean Val loss 0.099\n",
      "Training accuracy: 100.00% | Validation accuracy: 87.50%\n",
      "Ep 11 (Step 005800): Train loss 0.082, Val loss 0.219\n",
      "Ep 11 (Step 006000): Train loss 0.031, Val loss 0.213\n",
      "Ep 11 (Step 006200): Train loss 0.059, Val loss 0.189\n",
      "[Epoch 11] mean Train loss 0.068, mean Val loss 0.106\n",
      "Training accuracy: 98.44% | Validation accuracy: 89.06%\n",
      "Ep 12 (Step 006400): Train loss 0.039, Val loss 0.189\n",
      "Ep 12 (Step 006600): Train loss 0.070, Val loss 0.196\n",
      "Ep 12 (Step 006800): Train loss 0.013, Val loss 0.163\n",
      "[Epoch 12] mean Train loss 0.056, mean Val loss 0.092\n",
      "Training accuracy: 98.44% | Validation accuracy: 90.62%\n",
      "Ep 13 (Step 007000): Train loss 0.010, Val loss 0.178\n",
      "Ep 13 (Step 007200): Train loss 0.040, Val loss 0.162\n",
      "Ep 13 (Step 007400): Train loss 0.179, Val loss 0.155\n",
      "[Epoch 13] mean Train loss 0.050, mean Val loss 0.087\n",
      "Training accuracy: 95.31% | Validation accuracy: 92.19%\n",
      "Ep 14 (Step 007600): Train loss 0.021, Val loss 0.173\n",
      "Ep 14 (Step 007800): Train loss 0.027, Val loss 0.155\n",
      "[Epoch 14] mean Train loss 0.046, mean Val loss 0.085\n",
      "Training accuracy: 100.00% | Validation accuracy: 93.75%\n",
      "Ep 15 (Step 008000): Train loss 0.158, Val loss 0.143\n",
      "Ep 15 (Step 008200): Train loss 0.021, Val loss 0.144\n",
      "Ep 15 (Step 008400): Train loss 0.116, Val loss 0.130\n",
      "[Epoch 15] mean Train loss 0.041, mean Val loss 0.082\n",
      "Training accuracy: 98.44% | Validation accuracy: 93.75%\n",
      "Ep 16 (Step 008600): Train loss 0.115, Val loss 0.134\n",
      "Ep 16 (Step 008800): Train loss 0.018, Val loss 0.127\n",
      "Ep 16 (Step 009000): Train loss 0.024, Val loss 0.129\n",
      "[Epoch 16] mean Train loss 0.038, mean Val loss 0.081\n",
      "Training accuracy: 100.00% | Validation accuracy: 93.75%\n",
      "Ep 17 (Step 009200): Train loss 0.014, Val loss 0.118\n",
      "Ep 17 (Step 009400): Train loss 0.051, Val loss 0.114\n",
      "Ep 17 (Step 009600): Train loss 0.003, Val loss 0.104\n",
      "[Epoch 17] mean Train loss 0.033, mean Val loss 0.075\n",
      "Training accuracy: 100.00% | Validation accuracy: 93.75%\n",
      "Ep 18 (Step 009800): Train loss 0.023, Val loss 0.113\n",
      "Ep 18 (Step 010000): Train loss 0.024, Val loss 0.111\n",
      "Ep 18 (Step 010200): Train loss 0.028, Val loss 0.105\n",
      "[Epoch 18] mean Train loss 0.035, mean Val loss 0.085\n",
      "Training accuracy: 100.00% | Validation accuracy: 93.75%\n",
      "Ep 19 (Step 010400): Train loss 0.035, Val loss 0.109\n",
      "Ep 19 (Step 010600): Train loss 0.005, Val loss 0.094\n",
      "Ep 19 (Step 010800): Train loss 0.084, Val loss 0.101\n",
      "[Epoch 19] mean Train loss 0.027, mean Val loss 0.075\n",
      "Training accuracy: 98.44% | Validation accuracy: 93.75%\n",
      "Ep 20 (Step 011000): Train loss 0.009, Val loss 0.097\n",
      "Ep 20 (Step 011200): Train loss 0.023, Val loss 0.092\n",
      "Ep 20 (Step 011400): Train loss 0.009, Val loss 0.100\n",
      "[Epoch 20] mean Train loss 0.027, mean Val loss 0.079\n",
      "Training accuracy: 98.44% | Validation accuracy: 93.75%\n",
      "Early stopping: 3 epoch boyunca anlamlı iyileşme yok. En iyi Val loss 0.0755 (epoch 17).\n",
      "Best weights geri yüklendi.\n",
      "Training completed in 421.66 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "#Optimizer olarak AdamW kullandım ve lr ile weight_decay değerlerini derste gördüğümüz örneğe göre biraz düşürdüm. (1.Eğitimde başarılı olmadı o değerler)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "num_epochs = 20 \n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simplev2(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=200,      # step içinde kısa örneklemle rapor\n",
    "    eval_iter=4,       # step içi değerlendirmede kaç batch taransın\n",
    "    early_stopping=True,\n",
    "    patience=3,         # 3 epoch iyileşme yoksa dur\n",
    "    min_delta=1e-3,     # val loss en az bu kadar düşerse \"iyileşme\" say\n",
    "    restore_best_weights=True,\n",
    "    checkpoint_path=\"phishing_classifier2_.pth\"  # istersen \"best.pt\" ver\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11363094-e0de-424d-adee-0b57e0c98e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"phishing_classifier2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0d70e47-f0ea-410f-8b45-8c6d7b3bc83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "metrics = { \"train_losses\": train_losses, \"val_losses\": val_losses, \"train_accs\": train_accs, \"val_accs\": val_accs, \"examples_seen\": examples_seen }\n",
    "with open(\"metrics2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metrics, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e11b258-8de3-4997-afd8-d60e31b2aa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9732108687332568, 'precision': 0.9845679012345679, 'recall': 0.9622926093514329, 'f1': 0.973302822273074, 'roc_auc': np.float64(0.9968937548123068), 'confusion_matrix': {'tn': 1267, 'fp': 20, 'fn': 50, 'tp': 1276}}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_full(val_loader, model, device, pad_id=50256):\n",
    "    model.eval()\n",
    "    tp = fp = tn = fn = 0\n",
    "    all_probs = []\n",
    "    all_y = []\n",
    "\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device, non_blocking=True)\n",
    "        yb = yb.to(device, non_blocking=True)\n",
    "\n",
    "        # Son geçerli token'ın indeksini bul\n",
    "        last_idx = (xb != pad_id).sum(dim=1) - 1\n",
    "\n",
    "        # Logits'i o pozisyondan al\n",
    "        logits_all = model(xb)                                  # [B, T, C]\n",
    "        logits = logits_all[torch.arange(xb.size(0), device=device), last_idx, :]  # [B, C]\n",
    "\n",
    "        preds = torch.argmax(logits, dim=-1)                    # [B]\n",
    "        probs = torch.softmax(logits, dim=-1)[:, 1]             # positive sınıf olasılığı\n",
    "\n",
    "        # Confusion matrix bileşenleri\n",
    "        tp += ((preds == 1) & (yb == 1)).sum().item()\n",
    "        tn += ((preds == 0) & (yb == 0)).sum().item()\n",
    "        fp += ((preds == 1) & (yb == 0)).sum().item()\n",
    "        fn += ((preds == 0) & (yb == 1)).sum().item()\n",
    "\n",
    "        all_probs.append(probs.detach().cpu())\n",
    "        all_y.append(yb.detach().cpu())\n",
    "\n",
    "    # Temel metrikler\n",
    "    total = tp + tn + fp + fn\n",
    "    acc = (tp + tn) / max(1, total)\n",
    "    precision = tp / max(1, tp + fp)\n",
    "    recall = tp / max(1, tp + fn)\n",
    "    f1 = 2 * precision * recall / max(1e-12, (precision + recall))\n",
    "\n",
    "    # ROC-AUC (ranks yöntemi; sklearn yok)\n",
    "    y_true = torch.cat(all_y).numpy()\n",
    "    scores = torch.cat(all_probs).numpy()\n",
    "    pos = (y_true == 1)\n",
    "    n_pos = int(pos.sum())\n",
    "    n_neg = len(y_true) - n_pos\n",
    "\n",
    "    auc = None\n",
    "    if n_pos > 0 and n_neg > 0:\n",
    "        order = np.argsort(scores)\n",
    "        ranks = np.empty_like(order)\n",
    "        ranks[order] = np.arange(len(scores)) + 1\n",
    "        sum_ranks_pos = ranks[pos].sum()\n",
    "        auc = (sum_ranks_pos - n_pos * (n_pos + 1) / 2) / (n_pos * n_neg)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "        \"roc_auc\": auc, \n",
    "        \"confusion_matrix\": {\"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp},\n",
    "    }\n",
    "\n",
    "metrics = eval_full(val_loader, model, device)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9047bb73-fb42-419c-b524-96bb284200f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = eval_full(test_loader, model, device, pad_id=50256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39078c03-56aa-4534-9808-0f8bc4fd815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9686544342507645,\n",
       " 'precision': 0.9734375,\n",
       " 'recall': 0.9629057187017002,\n",
       " 'f1': 0.9681429681429681,\n",
       " 'roc_auc': np.float64(0.9965627462488338),\n",
       " 'confusion_matrix': {'tn': 644, 'fp': 17, 'fn': 24, 'tp': 623}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea9a889-ce8a-4a1b-896f-38bc95533be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TF-IDF vs fine-tuned GPT2-small \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = train_df[\"Email Text\"].astype(str).values\n",
    "y_train = train_df[\"Email Type\"].astype(int).values\n",
    "\n",
    "X_val   = validation_df[\"Email Text\"].astype(str).values\n",
    "y_val   = validation_df[\"Email Type\"].astype(int).values\n",
    "\n",
    "X_test  = test_df[\"Email Text\"].astype(str).values\n",
    "y_test  = test_df[\"Email Type\"].astype(int).values\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        lowercase=False,\n",
    "        strip_accents=\"unicode\",   \n",
    "        sublinear_tf=True\n",
    "    )),\n",
    "    (\"lr\", LogisticRegression(\n",
    "        max_iter=2000,\n",
    "        n_jobs=None,               \n",
    "        solver=\"liblinear\"        \n",
    "    ))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"tfidf__ngram_range\": [(1,1), (1,2)],\n",
    "    \"tfidf__min_df\": [2, 5],\n",
    "    \"tfidf__max_features\": [None, 100_000],\n",
    "    \"lr__C\": [0.5, 1.0, 2.0],\n",
    "    \"lr__penalty\": [\"l2\"]        \n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",       \n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "baseline = gs.best_estimator_\n",
    "\n",
    "# === 3) Validation ve Test performansı ===\n",
    "def evaluate(model, X, y):\n",
    "    proba = model.predict_proba(X)[:,1]\n",
    "    pred  = (proba >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y, pred),\n",
    "        \"precision\": precision_score(y, pred, zero_division=0),\n",
    "        \"recall\":    recall_score(y, pred, zero_division=0),\n",
    "        \"f1\":        f1_score(y, pred, zero_division=0),\n",
    "        \"roc_auc\":   roc_auc_score(y, proba),\n",
    "        \"confusion_matrix\": confusion_matrix(y, pred, labels=[0,1])\n",
    "    }\n",
    "\n",
    "baseline_val  = evaluate(baseline, X_val,  y_val)\n",
    "baseline_test = evaluate(baseline, X_test, y_test)\n",
    "\n",
    "# GPT2 test veri setindeki sonuçlarım.\n",
    "gpt2_test = {\n",
    "    \"accuracy\": 0.9686544342507645,\n",
    "    \"precision\": 0.9734375,\n",
    "    \"recall\": 0.9629057187017002,\n",
    "    \"f1\": 0.9681429681429681,\n",
    "    \"roc_auc\": 0.9965627462488338,\n",
    "    \"confusion_matrix\": np.array([[644, 17],[24, 623]])\n",
    "}\n",
    "\n",
    "\n",
    "def plot_compare(baseline_metrics, gpt2_metrics, title_suffix=\"(Test Set)\"):\n",
    "    labels = [\"Accuracy\",\"Precision\",\"Recall\",\"F1\",\"ROC-AUC\"]\n",
    "    base_vals = [baseline_metrics[k.lower()] for k in [\"ACCURACY\",\"PRECISION\",\"RECALL\",\"F1\",\"ROC_AUC\"]]\n",
    "    gpt2_vals = [gpt2_metrics[k.lower()]    for k in [\"ACCURACY\",\"PRECISION\",\"RECALL\",\"F1\",\"ROC_AUC\"]]\n",
    "\n",
    "    x = np.arange(len(labels))\n",
    "    w = 0.35\n",
    "    plt.figure(figsize=(9,5))\n",
    "    b1 = plt.bar(x - w/2, base_vals, width=w, label=\"TF-IDF + LR\")\n",
    "    b2 = plt.bar(x + w/2, gpt2_vals, width=w, label=\"GPT-2 Fine-tuned\")\n",
    "    for bars in [b1, b2]:\n",
    "        for b in bars:\n",
    "            h = b.get_height()\n",
    "            plt.text(b.get_x() + b.get_width()/2, h+0.01, f\"{h:.2f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.ylim(0,1.05)\n",
    "    plt.xticks(x, labels)\n",
    "    plt.title(f\"Performans Karşılaştırması {title_suffix}\")\n",
    "    plt.ylabel(\"Skor\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\", alpha=0.2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_compare(baseline_test, gpt2_test, \"(Test)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
